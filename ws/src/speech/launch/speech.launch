<launch>
    <!-- Flags to launch nodes -->
    <arg name="LAUNCH_DEVICES" default="True"/> <!-- AudioCapturer, say (Mic, Speaker) -->
    <arg name="SPEECH_PRE_PROCESSING" default="True"/> <!-- KWS, UsefulAudio (VAD) -->
    <arg name="LAUNCH_STT" default="True"/>
    <arg name="OFFLINE_SAY" default="True"/> <!-- Say words offline -->

    <!-- Args for node parameters -->
    <arg name="UA_THRESHOLD" default="0.7"/><!-- Threshold for speech detection -->
    <arg name="USE_RESPEAKER" default="True"/>
    <arg name="DISABLE_KWS" default="False"/> <!-- When disabled, the node can listen if many consecutive voiced frames are found -->
    <arg name="MAX_AUDIO_DURATION" default="15"/> <!-- Trim audio duration to this limit or stop before if speech not detected -->
    <arg name="STT_SERVICE" default="False"/> <!-- TODO: Add service to hear.py -->
    <arg name="STT_SERVER_IP" default="127.0.0.1:50051"/> <!-- IP address of the STT server -->

    <!-- Args for node debugging-->
    <arg name="DEBUG_WHISPER" default="False"/> <!-- Print execution time-->
    <arg name="DEBUG_SAY" default="True"/> <!-- Print spoken words -->
    <arg name="DEBUG_USEFUL_AUDIO" default="True"/> <!-- Print change in state -->
    <arg name="DEBUG_KWS" default="True"/> <!-- Print when keyword is detected -->
    <arg name="DEBUG_RESPEAKER" default="False"/> <!-- No debug implemented -->
    
    <!-- Devices -->
    <!-- Node: AudioCapturer -->
    <!-- Purpose: Captures audio from the microphone and publishes it as raw audio chunks -->
    <!-- Usage: This node publishes to the "rawAudioChunk" topic -->
    <node name="AudioCapturer" pkg="speech" type="AudioCapturer.py" respawn="true" output="screen" if="$(eval arg('LAUNCH_DEVICES'))">
        <param name="respeaker" value="$(arg USE_RESPEAKER)"/>    
    </node>

    <!-- Node: say -->
    <!-- Purpose: Handles text-to-speech functionality, converting text to speech using either an online or offline TTS engine -->
    <!-- Usage: This node subscribes to the "/speech/speak_now" topic and provides the "/speech/speak" service -->
    <node name="say" pkg="speech" type="Say.py" respawn="true" output="screen" if="$(eval arg('LAUNCH_DEVICES'))">
        <param name="offline" value="$(arg OFFLINE_SAY)"/>
        <param name="debug" value="$(arg DEBUG_SAY)"/>
    </node>

    <!-- Node: ReSpeaker -->
    <!-- Purpose: Interfaces with the ReSpeaker hardware to get the direction of arrival (DOA) of sound and control the LED ring -->
    <!-- Usage: This node publishes to the "DOA" topic and subscribes to the "ReSpeaker/light" topic -->
    <node name="ReSpeaker" pkg="speech" type="ReSpeaker.py" respawn="true" output="screen" if="$(eval arg('USE_RESPEAKER') and arg('LAUNCH_DEVICES'))">
        <param name="debug" value="$(arg DEBUG_RESPEAKER)"/>
    </node>

    <!-- Speech Pre-processing -->
    <!-- Node: KWS -->
    <!-- Purpose: Handles keyword spotting using Porcupine to detect keywords in the audio stream -->
    <!-- Usage: This node subscribes to the "rawAudioChunk" topic and publishes to the "keyword_detected" topic -->
    <node name="KWS" pkg="speech" type="KWS.py" output="screen" respawn="true" if="$(eval arg('SPEECH_PRE_PROCESSING') and not arg('DISABLE_KWS'))">
        <param name="debug" value="True"/>
    </node>

    <!-- Node: UsefulAudio -->
    <!-- Purpose: Processes audio segments to determine if they contain useful speech and publishes the useful audio -->
    <!-- Usage: This node subscribes to the "rawAudioChunk", "saying", and "keyword_detected" topics and publishes to the "UsefulAudio" topic -->
    <node name="UsefulAudio" pkg="speech" type="UsefulAudio.py" respawn="true" output="screen" if="$(eval arg('SPEECH_PRE_PROCESSING'))">
        <param name="debug" value="$(arg DEBUG_USEFUL_AUDIO)"/>
        <param name="threshold" value="$(arg UA_THRESHOLD)"/>
        <param name="DISABLE_KWS" value="$(arg DISABLE_KWS)"/>
        <param name="MAX_AUDIO_DURATION" value="$(arg MAX_AUDIO_DURATION)"/>
        <param name="STT_SERVICE" value="$(arg STT_SERVICE)"/>
    </node>

    <!-- Speech To Text -->
    <!-- Node: hear -->
    <!-- Purpose: Handles speech-to-text functionality, converting speech to text using either an online or offline STT engine -->
    <!-- Usage: This node subscribes to the "UsefulAudio" topic and publishes to the "UsefulAudioAzure" and "UsefulAudioWhisper" topics -->
    <node name="hear" pkg="speech" type="Hear.py" respawn="true" output="screen" if="$(eval arg('LAUNCH_STT'))">
        <param name="STT_SERVER_IP" value="$(arg STT_SERVER_IP)" />
    </node>

</launch>
