<launch>
	<!-- Comment both to use openai's API -->
	<arg name="BASE_URL" default="http://localhost:11434/v1" />
	<arg name="MODEL" default="llama3.2" />
	<!-- <arg name="BASE_URL" default="None" /> -->
	<!-- <arg name="MODEL" default="gpt-4o-2024-08-06" /> -->
	<node name="command_interpreter" pkg="frida_language_processing" type="command_interpreter_v2.py" output="screen" />
	<node name="conversation" pkg="frida_language_processing" type="conversation.py" />
	<!-- <node name="stop_listener" pkg="frida_language_processing" type="stop_listener.py" output="screen" /> -->
	<!-- <node name="item_categorization" pkg="frida_language_processing" type="item_categorization.py" output="screen" /> -->
	<node name="guest_analyzer" pkg="frida_language_processing" type="guest_analyzer.py" output="screen" />
	<node name="data_extractor" pkg="frida_language_processing" type="extract_data.py" output="screen">
		<param name="base_url" value="$(arg BASE_URL)" />
		<param name="model" value="$(arg MODEL)" />
	</node>
</launch>
